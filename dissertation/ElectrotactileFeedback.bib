@inproceedings{10.1145/3491102.3501863,
    author = {Alotaibi, Yosuef and Williamson, John H and Brewster, Stephen Anthony},
    title = {First Steps Towards Designing Electrotactons: Investigating Intensity and Pulse Frequency as Parameters for Electrotactile Cues},
    year = {2022},
    isbn = {9781450391573},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/3491102.3501863},
    doi = {10.1145/3491102.3501863},
    abstract = {Electrotactile stimulation is a novel form of haptic feedback. There is little work investigating its basic design parameters and how they create effective tactile cues. This paper describes two experiments that extend our knowledge of two key parameters. The first investigated the combination of pulse width and amplitude (Intensity) on sensations of urgency, annoyance, valence and arousal. Results showed significant effects: increasing Intensity caused higher ratings of urgency, annoyance and arousal but reduced valence. We established clear levels for differentiating each sensation. A second study then investigated Intensity and Pulse Frequency to find out how many distinguishable levels could be perceived. Results showed that both Intensity and Pulse Frequency significantly affected perception, with four distinguishable levels of Intensity and two of Pulse Frequency. These results add significant new knowledge about the parameter space of electrotactile cue design and help designers select suitable properties to use when creating electrotactile cues.},
    booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
    articleno = {215},
    numpages = {11},
    keywords = {pulse frequency, interaction design, intensity, Electrotactile feedback},
    location = {, New Orleans, LA, USA, },
    series = {CHI '22}
}

@INPROCEEDINGS{9086329,
  author={Alotaibi, Yosuef and Williamson, John H and Brewster, Stephen},
  booktitle={2020 IEEE Haptics Symposium (HAPTICS)}, 
  title={Investigating Electrotactile Feedback on The Hand}, 
  year={2020},
  volume={},
  number={},
  pages={637-642},
  keywords={Electrical stimulation;Skin;Space exploration;Haptic interfaces},
  doi={10.1109/HAPTICS45997.2020.ras.HAP20.13.8ee5dc37}}

@inproceedings{10.1145/1322192.1322222,
    author = {Hoggan, Eve and Brewster, Stephen},
    title = {Designing audio and tactile crossmodal icons for mobile devices},
    year = {2007},
    isbn = {9781595938176},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/1322192.1322222},
    doi = {10.1145/1322192.1322222},
    abstract = {This paper reports an experiment into the design of crossmodal icons which can provide an alternative form of output for mobile devices using audio and tactile modalities to communicate information. A complete set of crossmodal icons was created by encoding three dimensions of information in three crossmodal auditory/tactile parameters. Earcons were used for the audio and Tactons for the tactile crossmodal icons. The experiment investigated absolute identification of audio and tactile crossmodal icons when a user is trained in one modality and tested in the other (and given no training in the other modality) to see if knowledge could be transferred between modalities. We also compared performance when users were static and mobile to see any effects that mobility might have on recognition of the cues. The results showed that if participants were trained in sound with Earcons and then tested with the same messages presented via Tactons they could recognize 85\% of messages when stationary and 76\% when mobile. When trained with Tactons and tested with Earcons participants could accurately recognize 76.5\% of messages when stationary and 71\% of messages when mobile. These results suggest that participants can recognize and understand a message in a different modality very effectively. These results will aid designers of mobile displays in creating effective crossmodal cues which require minimal training for users and can provide alternative presentation modalities through which information may be presented if the context requires.},
    booktitle = {Proceedings of the 9th International Conference on Multimodal Interfaces},
    pages = {162–169},
    numpages = {8},
    keywords = {crossmodal interaction, earcons, mobile interaction, multimodal interaction, tactons (tactile icons)},
    location = {Nagoya, Aichi, Japan},
    series = {ICMI '07}
}

@book{hand_book,
    author = {Jones, Lynette A. and Lederman, Susan J.},
    title = "{Human Hand Function}",
    publisher = {Oxford University Press},
    year = {2006},
    month = {05},
    abstract = "{This book reviews the sensory and motor aspects of normal hand function from both neurophysiological and behavioral perspectives. Hand function is presented as a continuum ranging from activities that are essentially sensory in nature to those that have a strong motor component. Four functional categories are delineated along this sensorimotor continuum: tactile sensing, active haptic sensing, prehension, and non-prehensile skilled movements. The continuum is used as a conceptual framework for analyzing and synthesizing a broad range of studies that pertain to normal human hand function. The book begins with a historical overview of research on the hand and a discussion of the evolutionary development of the anatomical structure of the hand. In subsequent chapters, research pertaining to the four categories is reviewed, e.g., intensive, spatial, temporal, and thermal sensitivity of the hand, role of hand movements in recognizing common objects, control of reaching and grasping movements, and organization of keyboard skills. The book examines how sensory and motor function develops in the hand from birth to old age, and how the specific end effector(s) used to interact with the environment influences the nature of the information obtained and task performance. It closes with an assessment of how basic research on the hand has contributed to an array of applied domains, including communication systems for the blind, haptic interfaces for teleoperation and virtual-environment applications, tests for assessing hand impairments, and haptic art.}",
    isbn = {9780195173154},
    doi = {10.1093/acprof:oso/9780195173154.001.0001},
    url = {https://doi.org/10.1093/acprof:oso/9780195173154.001.0001},
    pages = {1–280}
}

@INPROCEEDINGS{artificial_skin,
  author={Franceschi, M. and Seminara, L. and Pinna, L. and Dosen, S. and Farina, D. and Valle, M.},
  booktitle={2015 37th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)}, 
  title={Preliminary evaluation of the tactile feedback system based on artificial skin and electrotactile stimulation}, 
  year={2015},
  volume={},
  number={},
  pages={4554-4557},
  keywords={Skin;Prosthetics;Electrodes;Tactile sensors;Training;Polymers},
  doi={10.1109/EMBC.2015.7319407}
}

@misc{phrases_dataset,
  author = "Kenrick C. Mackenzie",
  title = "Design and Evaluation of a High-Fidelity Haptic Display for Teleoperators and Virtual Environments",
  howpublished = "\url{https://www.yorku.ca/mack/chi03b.html}",
  note = "[Online; accessed March 1, 2024]"
}

@inproceedings{blind_study,
author = {Metatla, Oussama and Oldfield, Alison and Ahmed, Taimur and Vafeas, Antonis and Miglani, Sunny},
title = {Voice User Interfaces in Schools: Co-designing for Inclusion with Visually-Impaired and Sighted Pupils},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300608},
doi = {10.1145/3290605.3300608},
abstract = {Voice user interfaces (VUIs) are increasingly popular, particularly in homes. However, little research has investigated their potential in other settings, such as schools. We investigated how VUIs could support inclusive education, particularly for pupils with visual impairments (VIs). We organised focused discussions with educators at a school, with support staff from local authorities and, through bodystorming, with a class of 27 pupils. We then ran a series of co-design workshops with participants with mixed-visual abilities to design an educational VUI application. This provided insights into challenges faced by pupils with VIs in mainstream schools, and opened a space for educators, sighted and visually impaired pupils to reflect on and design for their shared learning experiences through VUIs. We present scenarios, a design space and an example application that show novel ways of using VUIs for inclusive education. We also reflect on co-designing with mixed-visual-ability groups in this space.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {co-design, education, inclusion, visual impairment, voice user interfaces},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{rings_and_watch,
author = {Stanke, Dennis and Duente, Tim and Rohs, Michael},
title = {TactileWear: A Comparison of Electrotactile and Vibrotactile Feedback on the Wrist and Ring Finger},
year = {2020},
isbn = {9781450375795},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3419249.3420107},
doi = {10.1145/3419249.3420107},
abstract = {Wearables are getting more and more powerful. Tasks like notifications can be delegated to smartwatches. But the output capabilities of wearables seem to be stuck at displays and vibration. Electrotactile feedback may serve as an energy-efficient alternative to standard vibration feedback. We developed prototypes of wristbands and rings and conducted two studies to compare electrotactile and vibrotactile feedback. The prototypes have either four electrodes for electrotactile feedback or four actuators for vibration feedback. In a first study we analyzed the localization characteristics of the created stimuli. The results suggest more strongly localized sensations for electrotactile feedback, compared to vibrotactile feedback, which was more diffuse. In a second study we created notification patterns for both modalities and evaluated recognition rates, verbal associations, and satisfaction. Although the recognition rates were higher with electrotactile feedback, vibrotactile feedback was judged as more comfortable and less stressful. Overall, the results show that electrotactile feedback can be a viable alternative to vibrotactile feedback for wearables, especially for notification rings.},
booktitle = {Proceedings of the 11th Nordic Conference on Human-Computer Interaction: Shaping Experiences, Shaping Society},
articleno = {74},
numpages = {13},
keywords = {Electrotactile Feedback, Haptic Perception, Notification, Tactile Pattern, Vibration, Wearable Computing},
location = {Tallinn, Estonia},
series = {NordiCHI '20}
}

@INPROCEEDINGS{vibro_wearables,
  author={Matscheko, Michael and Ferscha, Alois and Riener, Andreas and Lehner, Manuel},
  booktitle={International Symposium on Wearable Computers (ISWC) 2010}, 
  title={Tactor placement in wrist worn wearables}, 
  year={2010},
  volume={},
  number={},
  pages={1-8},
  keywords={Wrist;Face;Visualization;Watches;Vibrations;Software;Humans;Vibro-tactile Stimulation;Subliminal Perception;Tactile Display;Perception Performance},
  doi={10.1109/ISWC.2010.5665867}
}

@inbook{multimodal_feedback,
author = {Freeman, Euan and Wilson, Graham and Vo, Dong-Bach and Ng, Alex and Politis, Ioannis and Brewster, Stephen},
title = {Multimodal feedback in HCI: haptics, non-speech audio, and their applications},
year = {2017},
isbn = {9781970001679},
publisher = {Association for Computing Machinery and Morgan \& Claypool},
url = {https://doi.org/10.1145/3015783.3015792},
abstract = {Computer interfaces traditionally depend on visual feedback to provide information to users, with large, high-resolution screens the norm. Other sensory modalities, such as haptics and audio, have great potential to enrich the interaction between user and device to enable new types of interaction for new user groups in new contexts. This chapter provides an overview of research in the use of these non-visual modalities for interaction, showing how new output modalities can be used in the user interface to different devices. The modalities that will be discussed include:Haptics: tactons (vibrotactile feedback), thermal (warming and cooling feedback), force feedback, and deformable devices;Non-Speech Audio: auditory icons, Earcons, musicons, sonification, and spatial audio output.One motivation for using multiple modalities in a user interface is that interaction can be distributed across the different senses or control capabilities of the person using it. If one modality is fully utilized or unavailable (e.g., due to sensory or situational impairment), then another can be exploited to ensure the interaction succeeds. For example, when walking and using a mobile phone, a user needs to focus their visual attention on the environment to avoid bumping into other people. A complex visual interface on the phone may make this difficult. However, haptic or audio feedback would allow them to use their phone and navigate the world at the same time.This chapter does not present background on multisensory perception and multimodal action, but for insights on that topic see Chapter 2. Chapter 3 also specifically discuss multisensory haptic interaction and the process of designing for it. As a complement, this chapter presents a range of applications where multimodal feedback that involves haptics or non-speech audio can provide usability benefits, motivated by Wickens' Multiple Resources Theory [Wickens 2002]. The premise of this theory is that tasks can be performed better and with fewer cognitive resources when they are distributed across modalities. For example, when driving, which is a largely visual task, route guidance is better presented through sound rather than a visual display, as that would compete with the driving for visual cognitive resources. Making calls or texting while driving, both manual tasks, would be more difficult to perform compared to voice dialing, as speech and manual input involve different modalities. For user interface design, it is important to distribute different tasks across modalities to ensure the user is not overloaded so that interaction can succeed.},
booktitle = {The Handbook of Multimodal-Multisensor Interfaces: Foundations, User Modeling, and Common Modality Combinations - Volume 1},
pages = {277–317},
numpages = {41}
}

@phdthesis{Alotaibi2023,
  author       = {Yosuef Alotaibi},
  title        = {Electrotactons: designing and evaluating electrotactile cues},
  school       = {University of Glasgow},
  year         = {2023},
  type         = {PhD thesis},
  url          = {https://theses.gla.ac.uk/id/eprint/83662},
  doi          = {10.5525/gla.thesis.83662},
  abstract     = {Electrotactile feedback is a novel haptic feedback modality that can be used to evoke a desired level of alertness and emotion or convey multidimensional information to the user. However, there is a lack of research investigating its basic design parameters and how they can be used to create effective tactile cues. This thesis investigates the effect of Electrotactile feedback on the subjective perception of specific sensations, such as urgency, annoyance, valence and arousal, to find the number of distinguishable levels in each sensation. These levels are then used for designing structured, abstract, electrotactile messages called Electrotactons. These have potential benefits over vibration-based cues due to the greater flexibility of the actuators. Experiments 1, 2 & 4 investigated the effects of manipulating the basic electrotactile parameters pulse width, amplitude and pulse frequency on perceived sensations. The results showed that all parameters have a significant effect on the perceived sensations, except for pulse frequency not having an effect on valence. Also, pulse frequencies of 30 PPS and above did not influence the perceived sensations. Experiment 3 investigated the use of pulse width, amplitude and pulse frequency to convey three types of information simultaneously encoded into an electrotactile cue. This was the first attempt to design Electrotactons using the basic parameters of electrotactile feedback. The results showed overall recognition rates of 38.19% for the complete Electrotactons. For the individual component parameters, pulse width had a recognition rate of 71.67%, amplitude 70.27%, and pulse frequency 66.36%. Experiment 5 investigated intensity and pulse frequency to determine how many distinguishable levels could be perceived. Results showed that both intensity and pulse frequency significantly affected perception, with four distinguishable levels of intensity and two of pulse frequency. Experiment 6 investigated the use of intensity and pulse frequency from in Experiment 5 to improve the design of Electrotactons on three body locations using two different size electrodes. The results showed overall recognition rates of up to 65.31% for the complete Electrotactons. For the individual component parameters, intensity had a recognition rate of 68.68%, and pulse frequency 94.41%. These results add significant new knowledge about the parameter space of electrotactile cue design and help designers select suitable properties to use when creating electrotactile cues.},
  timestamp    = {2023-06-23 08:27:56},
  supervisor   = {Stephen Brewster},
  supervisor-email = {Stephen.Brewster@glasgow.ac.uk},
}

@ARTICLE{yoshimoto,
  author={Yoshimoto, Shunsuke and Kuroda, Yoshihiro and Imura, Masataka and Oshiro, Osamu},
  journal={IEEE Transactions on Haptics}, 
  title={Material Roughness Modulation via Electrotactile Augmentation}, 
  year={2015},
  volume={8},
  number={2},
  pages={199-208},
  keywords={Electrodes;Materials;Haptic interfaces;Frequency modulation;Vibrations;Skin;Texture modulation;roughness;electrotactile display;augmented reality;Texture modulation;roughness;electrotactile display;augmented reality},
  doi={10.1109/TOH.2015.2412942}
}

@ARTICLE{Stephens-Fripp,
  author={Stephens-Fripp, Benjamin and Alici, Gursel and Mutlu, Rahim},
  journal={IEEE Access}, 
  title={A Review of Non-Invasive Sensory Feedback Methods for Transradial Prosthetic Hands}, 
  year={2018},
  volume={6},
  number={},
  pages={6878-6899},
  keywords={Prosthetic hand;Vibrations;Skin;Sensors;Surgery;Implants;Sensory feedback;prosthetics;non-invasive;electrotactile stimulation;mechanotactile stimulation;vibrotactile stimulation},
  doi={10.1109/ACCESS.2018.2791583}
}

@inproceedings{duente2023colorful,
  author = {Duente, Tim and Schulte, Justin and Lucius, Malte and Rohs, Michael},
  title = {Colorful Electrotactile Feedback on the Wrist},
  booktitle = {Proceedings of the International Conference on Mobile and Ubiquitous Multimedia (MUM '23)},
  year = {2023},
  month = {December 03--06},
  address = {Vienna, Austria},
  publisher = {ACM},
  location = {New York, NY, USA},
  pages = {13},
  url = {https://doi.org/10.1145/3626705.3627800},
}
